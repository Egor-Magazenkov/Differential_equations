\documentclass[a5paper, 10pt]{article}

% Текст
\usepackage[utf8]{inputenc} % UTF-8 кодировка
\usepackage[russian]{babel} % Русский язык
\usepackage{indentfirst} % красная строка в первом параграфе в главе
% Отображение страниц
\usepackage{geometry} % размеры листа и отступов
\geometry{
	left=12mm,
	top=25mm,
	right=15mm,
	bottom=17mm,
	marginparsep=0mm,
	marginparwidth=0mm,
	headheight=10mm,
	headsep=7mm,
	nofoot}
\usepackage{afterpage,fancyhdr} % настройка колонтитулов
\pagestyle{fancy}
\fancypagestyle{style}{ % создание нового стиля style
	\fancyhf{} % очистка колонтитулов
	\fancyhead[LO, RE]{Дифференциальные уравнения} % название документа наверху
	\fancyhead[RO, LE]{\leftmark} % название section наверху
	\fancyfoot[RO, LE]{\thepage} % номер страницы справа внизу на нечетных и слева внизу на четных
	\renewcommand{\headrulewidth}{0.25pt} % толщина линии сверху
	\renewcommand{\footrulewidth}{0pt} % толцина линии снизу
}
\fancypagestyle{plain}{ % создание нового стиля plain -- полностью пустого
	\fancyhf{}
	\renewcommand{\headrulewidth}{0pt}
}
\fancypagestyle{title}{ % создание нового стиля title -- для титульной страницы
	\fancyhf{}
	\fancyhead[C]{{\footnotesize
			Министерство образования и науки Российской Федерации\\
			Федеральное государственное автономное образовательное учреждение высшего образования
	}}
	\fancyfoot[C]{{\large 
			Санкт-Петербург, 2022-2023
	}}
	\renewcommand{\headrulewidth}{0pt}
}

% Математика
\usepackage{amsmath, amsfonts, amssymb, amsthm} % Набор пакетов для математических текстов
\usepackage{dmvnbase} % мехматовский пакет latex-сокращений
\usepackage{cancel} % зачеркивание для сокращений
% Рисунки и фигуры
\usepackage[pdftex]{graphicx} % вставка рисунков
\usepackage{wrapfig} % вставка фигур, обтекая текст
\usepackage{subcaption} % расположение нескольких объектов внутри одной фигуры
\usepackage{caption} % для настройки подписей
\captionsetup{figurewithin=none,labelsep=period, font={small,it}} % настройка подписей к рисункам
% Рисование
\usepackage{tikz} % рисование
\usepackage{pgfplots} % графики
% Таблицы
\usepackage{multirow} % объединение строк
\usepackage{multicol} % объединение столбцов
% Остальное
\usepackage[unicode, pdftex]{hyperref} % гиперссылки
\usepackage{enumitem} % нормальное оформление списков
\setlist{itemsep=0.15cm,topsep=0.15cm,parsep=1pt} % настройки списков
% Теоремы, леммы, определения...
\theoremstyle{definition}
\newtheorem{Def}{Определение}
\newtheorem*{Axiom}{Аксиома}
\theoremstyle{plain}
\newtheorem{Th}{Теорема}
\newtheorem{Lem}{Лемма}
\newtheorem{Cor}{Следствие}
\newtheorem*{Prop}{Предложение}
\newtheorem{Ex}{Пример}
\theoremstyle{remark}
\newtheorem*{Note}{Замечание}
\newtheorem*{Solution}{Решение}
\newtheorem*{Proof}{Доказательство}
% Свои команды
\newcommand{\comb}[1]{\left[\hspace{-4pt}\begin{array}{l}#1\end{array}\right.\hspace{-5pt} } % совокупность уравнений
% Титульный лист
\newcommand*{\titlePage}{
	\thispagestyle{title}
	\begingroup
	\begin{center}
%		{\footnotesize
%			Министерство образования и науки Российской Федерации\\
%			Федеральное государственное автономное образовательное учреждение высшего образования
%		}
%		
		\vspace*{6ex}
		
		{\small
			САНКТ-ПЕТЕРБУРГСКИЙ НАЦИОНАЛЬНЫЙ ИССЛЕДОВАТЕЛЬСКИЙ УНИВЕРСИТЕТ ИНФОРМАЦИОННЫХ ТЕХНОЛОГИЙ, МЕХАНИКИ И ОПТИКИ	
		}
		
		\vspace*{2ex}
		
		{\normalsize
			Факультет систем управления и робототехники
		}
		
		\vspace*{15ex}
		
		{\Large \bfseries 
			Дифференциальные уравнения
		}
	\end{center}
	\vspace*{20ex}
	\begin{flushright}
		{\large 
			\underline{Выполнил}: студент гр. \textbf{R32353}\\
			\begin{flushright}
				\textbf{Магазенков Е. Н.}\\
			\end{flushright}
		}
		
		\vspace*{5ex}
		
		{\large 
			\underline{Преподаватель}: \textit{Бабушкин М. В.}
		}
	\end{flushright}	
	\newpage
	\setcounter{page}{1}
	\endgroup}
	


\begin{document}
	\titlePage
	\pagestyle{style}
	\part{}
	\section[ЛУ 1-ого порядка]{Линейные уравнения 1-ого порядка}
	\begin{Def}
		Дифференциальное уравнение вида 
		\begin{equation}
			y' = p(x) y + q(x),
		\end{equation}
		называют линейным неоднородным дифференциальным уравнением первого порядка (\textsc{ЛНУ} или просто \textsc{ЛУ}).
	\end{Def}
	
	\begin{Def}
		Дифференциальное уравнение вида 
		\begin{equation}
			y' = p(x) y
		\end{equation}
		называют линейным однородным дифференциальным уравнением первого порядка (\textsc{ЛОУ}).
	\end{Def}
	\begin{Note}
		Вообще, мы уже неоднократно сталкивались и решали уравнения такого вида. Однако для строгого обоснования наших решений рассмотрим следующую лемму.
	\end{Note}
	\begin{Lem}[Общее решение ЛОУ]
		Пусть в линейном однородном уравнении $y' = p(x) y$ функция $p(x) \in C\hr{a,b}$.
		
		Тогда его общее решение имеет вид \begin{equation}
			y = c\cdot e^{\int\!p},
		\end{equation}
		где $c\in \R$ -- произвольная константа и под $\int \!p$ понимается какая-то производная функции $p(x)$.
		\begin{Proof}
			Воспользуемся эквивалентным преобразованием
			\[
			y'=p(x)y \Leftrightarrow dy = p(x) y dx.
			\]
			Рассмотрим несколько возможных случаев:
			\begin{enumerate}
				\item $y=0$ -- очевидно решение,
				\item при $y>0$: разделим на $y$ с обеих сторон
				\[
				\frac{dy}{y} = p(x) dx.
				\]
				Проинтегрируем обе части:
				\[
				\int \frac{dy}{y} = \int p(x) dx,
				\]				
				\[
				\ln y = \int p(x) dx,
				\]
				\[
				y = A\cdot e^{\int\!p}, \quad\text{где } A>0.
				\]
				\item при $y<0$: аналогично, но появляется минус, который можно засунуть в константу.
				\[
				y = B\cdot e^{\int\!p}, \quad\text{где } B<0.
				\]
				\item Осталось разобрать случай, когда интегральная кривая проходит через границу $y=0$. Однако, рассматривая все кривые, видно, что они заданы строго в одной полуплоскости относительно $y=0$:
				\[
				y = A\cdot e^{\int\!p} > 0, \quad\text{где } A>0, \quad y = B\cdot e^{\int\!p} < 0, \quad\text{где } B<0.
				\]
			\end{enumerate}
			Таким образом, действительно, общее решение ЛОУ можно записать в виде $	y = c\cdot e^{\int\!p}$.
		\end{Proof}
	\end{Lem}
	\begin{Note}
		Теперь мы строго доказали, ранее использовавшиеся факты. Как вывод из этого, мы получаем, что теперь можно каждый раз не решать ЛОУ, а просто пользоваться формулой. Или хотя бы всегда проверять, похоже ли решение на полученное в общем виде.
	\end{Note}
	\begin{Note}
		Далее мы будем рассматривать общее решение неоднородного уравнения. Мы используем достаточно интересный метод доказательства: так, мы предоставим какое-то решение, которое мы назовем общим, а далее докажем, что любое другое решение на самом деле задается именно нашим выражением. 
		
		Оказывается, что такой метод можно применять и для решения любых уравнений. Достаточно лишь показать, что представленное выражение является решением, а также, что любое другое произвольное решение задается этим выражением.
	\end{Note}
	\begin{Lem}[Общее решение ЛНУ]
		Пусть в линейном уравнении $y' = p(x) y + q(x)$ функции $p(x),\, q(x) \in C\hr{a,b}$.
		
		Тогда его общее решение имеет вид \begin{equation}
			y = \hr{\int q \cdot e^{-\int\!p} + c} \cdot e^{\int \! p},
		\end{equation}
		где $c\in \R$ -- произвольная константа и под $\int \!f$ понимается какая-то производная функции $f(x)$.
		\begin{Proof}
			\begin{itemize}
				\item Докажем, что данное данное множество решений включено в общее множество решений исходного уравнения. Проще говоря, проверим, правда ли, что представленное выражение является решением.
				
				Найдем $y'(x)$:
				\[
				y' = q\cdot e^{-\int\! p} \cdot e^{\int\!p} + \hr{\int q\cdot e^{-\int\!p} + c} \cdot p e^{\int\!p} = q + \hr{\int q\cdot e^{-\int\!p} + c} \cdot p e^{\int\!p}.
				\]
				Тогда, подставляя в исходное уравнение:
				\[
				q + \hr{\int q\cdot e^{-\int\!p} + c} \cdot p e^{\int\!p} \equiv p \cdot \hr{\int q \cdot e^{-\int\!p} + c} \cdot e^{\int \! p} + q,
				\]
				получаем верное тождество.
				\item Докажем, что произвольное решение задается формулой $y = \hr{\int q \cdot e^{-\int\!p} + c} \cdot e^{\int \! p}$.
				
				Пусть $\varphi \in \hr{\alpha,\beta}$ -- решение, не задающееся этой формулой.
				
				Рассмотрим $x_0 \in \hr{\alpha, \beta} : \; \varphi(x_0) = y_0$.
				
				Найдем такое $c \in \R$, что наше решение проходит через точку $\hr{x_0, y_0}$. 
				\[
				\left. \hr{\int q \cdot e^{-\int\!p} + c} \cdot e^{\int \! p} \right|_{x=x_0} = y_0,
				\]
				\[
				c = \left. \hr{y_0 \cdot e^{-\int\!p} - \int q\cdot e^{-\int\!p}} \right|_{x=x_0}.
				\]
				Пусть решение с этим $c$ -- решение $\psi$. Тогда мы получили два решения задачи Коши $y = \hr{\int q \cdot e^{-\int\!p} + c} \cdot e^{\int \! p}$ с начальными условиями $y(x_0) = y_0$ на интервале $\hr{\alpha,\beta}$. Так как $f(x, y) = p(x) y+q(x) \in C\hr(a,b)$, то по теореме об единственности решения задачи Коши $\varphi = \psi$, что противоречит предположению о том, что $\varphi$ не задается решением вида $	y = \hr{\int q \cdot e^{-\int\!p} + c} \cdot e^{\int \! p}$. 
				
				Таким образом, действительно любое решение можно представить в виде $y = \hr{\int q \cdot e^{-\int\!p} + c} \cdot e^{\int \! p}$.
			\end{itemize}
			Объединяя эти два факта, мы получаем, что показанное нами решение действительно является общим решением линейного дифференциального уравнения.
		\end{Proof}
	\end{Lem}
	
	\begin{Note}
		В итоге мы имеем формулу для решения ЛУ, в которую можно подставить нужные значения. Однако достаточно тяжело помнить ее наизусть, поэтому нужно иметь какой-то метод, который сможет нас привести к этому решению. Напомним, что любой метод, который будет давать решение вида $	y = \hr{\int q \cdot e^{-\int\!p} + c} \cdot e^{\int \! p}$ окажется верным, так как мы уже доказали, что это общее решение. 
	\end{Note}

	\begin{Prop}[Метод Лагранжа или метод вариации произвольной постоянной]
		Пусть стоит задача решить линейное уравнение $y'=p(x)y+q(x)$.
		
		Рассмотрим соответствующее однородное уравнение, то есть уравнение $y'=p(x)y$. Его общее решение мы знаем (либо можем найти): $y=c\cdot e^{\int\!p}$. 
		
		Рассмотрим теперь $c$ не как константу, а как функцию $c(x)$.
		
		Подставляя $y=c(x) \cdot e^{\int\!p}$ в исходное линейное уравнение, получаем:
		\[
		c'(x) \cdot e^{\int\!p} + \cancel{c(x) \cdot p e^{\int\!p}} = \cancel{p c(x) \cdot e^{\int\!p}} + q,
		\]
		\[
		c'(x) = q\cdot e^{-\int\!p}.
		\]
		Это уравнение мы снова можем решить:
		\[
		c(x) = \int q\cdot e^{-\int\!p} + \tilde{c}.
		\]
		Тогда, возвращаясь к решению однородного уравнения и подставляя $c$ туда, получаем
		\[
		y = \hr{\int q\cdot e^{-\int\!p} + \tilde{c}}\cdot e^{\int\!p},
		\]
		то есть общее решение линейного уравнения.
	\end{Prop}

	\section[Бернулли и Рикатти]{Уравнения Бернулли и Рикатти}
	\begin{Note}
		Существует огромное количество уравнений первого порядка, которые можно свести к линейному какой-либо заменой. В этом пункте будут разобраны такие уравнения, представленные в XVII веке Якобом Бернулли \footnote{Якоб Бернулли (1655--1705, Швейцария)} и Рикатти \footnote{Рикк\'{а}ти Якопо Франческо (1676--1754, Италия)}.
	\end{Note}
	
	\begin{Def}
		Уравнение вида 
		\begin{equation}
			y' = p(x) y + q(x) y^{\alpha},
		\end{equation}
		где $\alpha\neq \hc{0,1}$, называется дифференциальным уравнением Бернулли.
	\end{Def}
	
	\begin{Lem}
		Уравнение Бернулли $y' = p(x) y + q(x) y^{\alpha}$ при $y\neq0$ заменой $t = y^{1-\alpha}$ сводится к линейному дифференциальному уравнению.
		\begin{Proof}
			Рассмотрим уравнение Бернулли 
			\[
			y' = p(x) y + q(x) y^{\alpha}.
			\]
			Поделим обе части уравнения на $y^{\alpha}$:
			\[
			\frac{y'}{y^\alpha} = p(x) y^{1-\alpha} + q(x).
			\]
			Сделаем замену $t = y^{1-\alpha}$, тогда $t' = (1-\alpha)\frac{y'}{y^{\alpha}}$:
			\[
			\frac{1}{1-\alpha} t' = p(x) t + q(x),
			\]
			\[
			t' = \hr{1-\alpha}\hr{p(x) t + q(x)}.
			\]
			Получили линейное дифференциальное уравнение.
		\end{Proof}
	\end{Lem}
	
	\begin{Def}
		Уравнение вида 
		\begin{equation}
			y' = p(x) y^2 + q(x) y + r(x)
		\end{equation}
		называется дифференциальным уравнением Бернулли.
	\end{Def}
	\begin{Note}
		Уравнение Бернулли является частным случаем уравнения Рикатти при $r(x)\equiv 0$. Рикатти был знаком с семьей Бернулли, поэтому связь между этими уравнениями неслучайна.
	\end{Note}
	
	\begin{Lem}
		Пусть $\varphi$ -- какое-то решение уравнения Рикатти $y' = p(x) y^2 + q(x) y + r(x)$. Подстановка $y = z + \varphi$ сводит это уравнение к уравнению Бернулли.
		\begin{Proof}
			Найдем $y'$:
			\[
			y' = z' + \varphi'.
			\]
			Так как $\varphi$ -- решение уравнения Рикатти, то 
			\[
			\varphi' = p(x) \varphi^2 + q(x) \varphi + r(x).
			\]
			Тогда $y' = z' + p(x) \varphi^2 + q(x) \varphi + r(x)$.
			
			Подставим замену в уравнение Рикатти
			\[
				z' + p(x) \varphi^2 + q(x) \varphi + \cancel{r(x)} = p(x) (z+\varphi)^2 + q(x) (z+\varphi) + \cancel{r(x)},
			\]
			\[
				z' = z \underbrace{\hr{2p(x)\varphi + q(x)}}_{P(x)} + \underbrace{p(x)}_{Q(x)} z^2,
			\]
			\[
				z' = P(x) z + Q(x) z^2.
			\]
			Получили уравнение Бернулли для $\alpha=2$.
		\end{Proof}
	\end{Lem}
	
	\section[УПД]{Уравнение в полных дифференциалах}
	\begin{Def}
		Пусть существует функция $u$ такая, что $du = P(x,y)dx + Q(x,y)dy$ (то есть $u_x'=P$, $u_y'=Q$). Тогда уравнение вида 
		\begin{equation}
			P(x,y)dx + Q(x,y)dy = 0
		\end{equation}
		называется уравнением в полных дифференциалах (\textsc{УПД}).
	\end{Def}
	
	\begin{Th}[Общее решение УПД]
		Пусть $u \in C^1 (G)$, причем $u_x'=P$, $u_y'=Q$. Тогда функция $\varphi(x)$ является общим решением уравнения $P(x,y)dx + Q(x,y)dy = 0$ на интервале $\hr{\alpha, \beta}$ в том и только том случае, когда $\varphi \in C^{1} \hr{\alpha,\beta}$ и $\varphi$ неявно задается уравнением $u(x,y) = c$ при некотором $c\in \R$.
		\begin{Proof}
			\underline{Необходимость}:\\
			Так как $\varphi$ -- решение, то $\varphi \in C^{1} \hr{\alpha,\beta}$ и 
			\[
			P(x,\varphi(x))dx + Q(x,\varphi(x))d(\varphi(x)) \equiv 0,
			\]
			то есть 
			\[
			P(x,\varphi(x)) + Q(x,\varphi(x))\varphi'(x) \equiv 0.
			\]
			Заметим, что левая часть есть полная производная функции $u(x, \varphi(x))$.
			\[
			\frac{d}{dx} u(x,\varphi(x)) \equiv 0,
			\]
			\[
			u(x, \varphi(x)) \equiv c.
			\]
			Таким образом, получаем, что $\varphi$ действительно неявно задана уравнением $u(x,y)=c$.
			
			\underline{Достаточность}:\\
			Так как $\varphi$ неявно задана уравнением $u(x,y)=c$, то 
			\[
			u(x, \varphi(x)) \equiv c.
			\]
			Тогда \[
			\frac{d}{dx} u(x,\varphi(x)) \equiv 0,
			\]
			то есть 
			\[
			P(x,\varphi(x)) + Q(x,\varphi(x))\varphi'(x) \equiv 0.
			\]
			Так как $\varphi \in C^{1} \hr{\alpha,\beta}$, то $\varphi$ является решением уравнения $P(x,y)dx + Q(x,y)dy = 0$ по определению решения дифференциального уравнения.
		\end{Proof}
	\end{Th}

	\begin{Note}
	Назревает хороший вопрос: откуда эту функцию $u$ взять и почему вообще она существует?
	
	Пусть есть функция $u: u_x'=P, \; u_y' = Q, \; u\in C^2(G)$. Рассмотрим вторые производные:
	\[
	\left.
	\begin{split}
		u_xy''=P_y', \\
		u_yx'' = Q_x'
	\end{split}
	\right\} \implies P_y' = Q_x'.
	\]
	На основе этого утверждения появляется следующая теорема.
	\end{Note}
	
	\begin{Th}[Признак УПД]
		Пусть $P, Q \in C^1(G)$, причем $P_y' = Q_x'$, где $G$ -- односвязная область.
		Тогда существует функция $u : u_x' = P, u_y' = Q$. Кроме того, все такие функции имеют вид 
		\[
		u(\tilde{x}, \tilde{y}) = \int\limits_{\gamma(\tilde{x}, \tilde{y})} P(x,y)dx + Q(x,y)dy + c,
		\]
		где $c \in \R$, $\gamma(\tilde{x}, \tilde{y})$ -- кривая в области $G$, соединяющая точки $\hr{x_0,y_0}$ и $\hr{\tilde{x}, \tilde{y}}$.
	\end{Th}
	
	\begin{Note}
		Таким образом, при определенных условиях мы поняли, как можно найти эту функцию $u$. И далее, решая уравнение $u=c$, можем найти общее решение УПД.
		
		Однако вычисление данного криволинейного интеграла зачастую является непростой задачей, поэтому рассмотрим другие методы.
	\end{Note}
	
	 \begin{Def}
		Функция $u$ при условии $u_x'=P$, $u_y'=Q$ называется потенциалом поля $\hr{P,Q}$, а поле $\hr{P,Q}$ -- потенциальным полем. 
	\end{Def}
	
	\begin{Ex}
		\[
		e^{-y}dx - \hr{xe^{-y}+2y} dy = 0.
		\]
		\begin{Solution}
			Область определения уравнения есть $\R^2$ -- односвязное множество. 
			
			Рассмотрим производные коэффициентов $P=e^{-y}$ и $Q = \hr{xe^{-y}+2y}$:
			\[
				P_y' = -e^{-y} = Q_x'.
			\]
			Таким образом, по признаку -- это уравнение в полных дифференциалах. 
			
			Не будем вычислять криволинейный интеграл. Но рассмотрим систему
			\[
			\case{u'_x = e^{-y}, \\ 
					u_y' = -xe^{-y}-2y}.
			\]
			Рассмотрим потенциал в какой-то точке с фиксированной ординатой $y_0$: 
			\[
			u_x' (x, y_0) = e^{-y_0} \implies u(x, y_0) = \int e^{-y_0} dx = xe^{-y_0} + c(y_0).
			\]
			Подставляя во второе уравнение системы, получаем
			\[
			\hr{xe^{-y} + c(y)}_y' = -xe^{-y} - 2y,
			\]
			\[
			\cancel{-xe^{-y}} + c'(y) = \cancel{-xe^{-y}} - 2y,
			\]
			\[
			c' = -2y,
			\]
			\[
			c(y) = -y^2 + A.
			\]
			Таким образом, $u(x,y) = xe^{-y} -y^2 + A$, а значит уравнение $ xe^{-y} -y^2 = C$ задает решение УПД.
		\end{Solution}
	\end{Ex}
	
	\begin{Note}
		В примере был показан другой способ решения УПД, избегающий криволинейное интегрирование. Однако данный способ далеко не всегда оказывается возможен. По крайней мере, не всегда можно взять интеграл, чтобы найти $u(x, y_0)$ (при плохой области интеграл по прямой будет достаточно сложен).
	\end{Note}
	
	\begin{Def}
		Функция $\mu(x,y) \neq 0$ называется интегрирующим множителем уравнения $P(x,y)dx + Q(x,y)dy = 0$, если при домножении этого уравнения на $\mu$ получается уравнение в полных дифференциалах.
		\[
		\mu P(x,y)dx + \mu Q(x,y)dy = 0 \text{ --- УПД.}
		\]
	\end{Def}
	
	\begin{Note}
		Если $\mu$ -- интегрирующий множитель уравнения $P(x,y)dx + Q(x,y)dy = 0$, причем $\mu, P, Q \in C^1(G)$. Тогда $\hr{\mu P}_y' = \hr{\mu Q}_x'$. Расписывая производную получаем уравнение в частных производных
		\[
		\mu_y' P + \mu P_y' = \mu_x' Q + \mu Q_x'. 
		\] 
		Решать его оказывается совсем непросто, однако чисто теоретически это является способом нахождения интегрирующего множества.
		
		Однако стоит помнить, что нам не требуется находить общее решение. Нам достаточно лишь какое-то частное решение. Иногда его можно найти, как в следующем примере.
	\end{Note}
	\begin{Ex}
		Рассмотрим линейное уравнение
		\[
		y' = p(x) y + q(x), 
		\]
		где $p\neq 0$. Попробуем найти его интегрирующий множитель.
		\begin{Solution}
			Перепишем исходное уравнение 
			\[
			\hr{p(x) y + q(x)}dx - dy = 0.
			\]
			Заметим, что это уравнение не является уравнением в полным дифференциалах.
			
			Запишем уравнение для нахождения интегрирующего множителя.
			\[
			\mu_y' \hr{p(x) y + q(x)} + \mu p(x) = -\mu_x'.
			\]
			Будем искать интегрирующий множитель в виде $\mu = \mu(x)$. Тогда первое слагаемое слева обнулится
			\[
			\mu p(x) = -\mu_x',
			\]
			\[
			\mu = C e^{-\int\!p}.
			\]
			Так как нам нужно лишь какое-то решение, то рассмотрим любое $C$, например $C=1$.
			
			Таким образом, $\mu = e^{-\int\!p}$ -- интегрирующий множитель.
			
			Умножим на $\mu$ исходное уравнение
			\[
				y' e^{-\int\!p} = p(x) y e^{-\int\!p}+ q(x)e^{-\int\!p},
			\]
			\[
				y' e^{-\int\!p} - p(x) y e^{-\int\!p} = q(x)e^{-\int\!p}.
			\]
			Заметим, что в левой части стоит производная произведения $\hr{ye^{-\int\!p}}$
			\[
			\hr{ye^{-\int\!p}}= q(x)e^{-\int\!p},
			\]
			\[
			ye^{-\int\!p} = \int q(x)e^{-\int\!p} + A,
			\]
			\[
			y = \hr{\int q(x)e^{-\int\!p} + A}e^{\int\!p}.
			\]
			Таким образом, получили общее решение линейного уравнения, а значит решение привело к верному ответу.
		\end{Solution}
	\end{Ex}
	
	\begin{Note}
		Таким образом, мы получили еще один способ нахождения решения линейного уравнения, которым можно пользоваться на практике. Нужно запомнить интегрирующий множитель $\mu = e^{-\int\!p}$, а также свертывание в производную произведения.
	\end{Note}

	\part{Уравнения, не разрешимые относительно произодной}
	\section[Разрешимые уравнения]{Уравнение, разрешимое относительно производной}
	\begin{Ex}
		Уравнение $\hr{y'}^3 -2yx = 0$ очевидно является разрешимым относительно производной:
		$y' = \sqrt[3]{2yx}$.
	\end{Ex}
	\begin{Ex}\label{ex_4}
		Рассмотрим уравнение $(y'-2x)(y'+2x) = 0$.
		
		Рассмотрим отдельно решения уравнений $y'=2x$ и $y' = -2x$. Хочется сказать, что вместе эти решения дадут общее решение исходного. Однако это не так! Очевидно, что решениями являются параболы с ветвями вниз и вверх соответственно. Тогда можно посмотреть на кривую, содержащую левую ветвь одной из парабол и правую другой (Рис. \ref{pic1}). Это также интегральная кривая, так как она очевидно гладкая.
		\begin{figure}[h!]
			\centering
			\begin{tikzpicture}
				\begin{axis}[axis x line=center, axis y line=center]
					\addplot[domain=-3:3] {x^2};
					\addplot[domain=-3:3] {-x^2};
					\addplot[domain=-3:0, blue, thick] {-x^2};
					\addplot[domain=0:3, blue, thick] {x^2};
				\end{axis}				
			\end{tikzpicture}
		\caption{}\label{pic1}
		\end{figure}
		Оказывается, что только в точке с абсциссой $x=0$ возможны такие интегральные кривые, так как иначе гладкость не соблюдается.
	\end{Ex}

	\section{Метод введения параметра}
	\begin{Def}
		Функция $f: D \to \R$ задана параметрически соотношениями $x = \varphi(t), y = \psi(t)$, где $t\in I$, если $\varphi(I) = D$ и $\forall t\in I \; f(\varphi(t))=\psi(t)$.
	\end{Def}

	\begin{Note}
		Заметим, что определение можно переписать немного по-другому.
		Функция $f: D \to \R$ задана параметрически соотношениями $x = \varphi(t), y = \psi(t)$, где $t\in I$, если $\varphi(I) = D$ и множество $\hs{\hr{\varphi(t), \psi(t)} : t \in I}$ является графиком функции $f$.
		
		Нетрудно понять, что эти определения эквивалентны.
	\end{Note}

	\begin{Ex}
		Зададим функцию $f(x) = 1, x\in\hs{-1,1}$ параметрически.
		
		Например, $\case{x =\cos t,\\ y=1} \; t\in \R$. Очевидно, что это задание удовлетворяет определению.
	\end{Ex}
	\begin{Prop}
		Рассмотрим уравнение $F(x,y') = 0$ от двух переменных $x$ и $y'$. Пусть оно задает некоторую кривую $\gamma = \hc{\hr{x,y} | F(x,y') = 0}$ плоскости $xOy'$.
		
		Возьмем функцию $\varphi$ такую, что эта кривая является графиком функции $\varphi'$. 
		
		Тогда $F(x, \varphi'(x)) \equiv 0$. 
		
		Идея нахождения решения такого уравнения (в котором нельзя выразить $y'$) заключается в том, чтобы задать функцию $\gamma$ параметрически и найти $y$ также параметрически.
		
		Пусть $\varphi \in C^1\hr{\alpha,\beta}$, $\varphi' \neq 0$, $\psi\in C\hr{\alpha, \beta}$, причем эти функции задают параметрически наше уравнение $F(\varphi(t), \psi(t)) \equiv 0$.
		
		Тогда функция, задаваемая параметрически 
		\[
		\begin{cases}
			x = \varphi(t),\\
			y = g(t) = \int \psi(t)\varphi'(t)dt + c,
		\end{cases}
		\quad t \in \hr{\alpha, \beta}
		\]
		является решением уравнения $F(x, y')=0$.
		
		\begin{Note}
			Проверим, что функция действительно является решением.
			
			Во-первых, проверим, что такое задание действительно является функцией, то есть каждому $x$ соответствует ровно один $y$. Так как $\varphi'\neq 0$, то $\varphi$ строго возрастает и тогда $\varphi$ -- биекция. Рассматривая обратную $t=\varphi^{-1} (x)$, получаем $y=g \circ \varphi^{-1}$.  
			
			Во-вторых, проверим непрерывность и дифференцируемость решения. Так как $g \in C^{1}\hr{\alpha, \beta}$ и $\varphi^{-1} \in C^{1}\hr{\varphi(\alpha),\varphi(\beta)}$, то их композиция также непрерывно дифференцируема.
			
			В-третьих, проверим, что функция обращает наше уравнение в тождество.
			\[
			\left. F(x,y') \right|_{y=g\circ\varphi^{-1}(x)} = F\hr{x, \hr{g\circ \varphi^{-1}}'(x)}.
			\]
			Так как $\hr{g\circ \varphi^{-1}}'(x) = g'(\varphi^{-1}(x))\hr{\varphi^{-1}}'(x) = \hr{\psi(t)\varphi'(t)}_{t=\varphi'(x)} \cdot \frac{1}{\varphi'\hr{\varphi^{-1}(x)}} = \psi(\varphi^{-1}(x))$, то получаем
			\[
			F\hr{x, \hr{g\circ \varphi^{-1}}'(x)} = F\hr{x, \psi(\varphi^{-1}(x))} = F(\varphi(t), \psi(t)) \equiv 0.
			\]
			Таким образом, наша функция действительно действительно обращает выражение в нуль. А значит, эта функция является решением уравнения $F(x,y')~=~0$.
		\end{Note}
	\end{Prop}

	\begin{Ex}
		\[e^{y'} + y' = x.\]
		\begin{Solution}
			Параметризуем множество, задаваемое этим уравнением \[\hc{\hr{x,y'} :\; e^{y'} + y' = x}.\]
			
			Пусть $y'=t$. Тогда $x = e^t + t$.
			\begin{figure}[h!]
				\centering
				\begin{tikzpicture}
					\begin{axis}[axis x line=center, axis y line=center]
						\addplot[blue,no marks, domain=-5:5, samples=500] {e^x+x};
					\end{axis}
				\end{tikzpicture}
			\caption{}
			\end{figure}
		\begin{Note}[Основное соотношение метода введение параметра]
			\[
			dy=y_x'dx.
			\]
		\end{Note}
		Подставляя наши функции получаем
		\[
		dy = t \cdot d(e^t+t),
		\]
		\[
		dy = t \cdot \hr{e^t+1},
		\]
		\[
		y = \int t\cdot \hr{e^t+1} dt + c.
		\]
		В итоге мы пришли к той же самой формуле, что и доказали ранее. А значит подстановки подходят.
		
		Тогда следующая функция является решением
		\[
		\begin{cases}
			x= e^t+t,\\
			y = te^t-e^t+\frac12 t^2 + c
		\end{cases}
		\quad c\in \R, t \in \R.
		\]
		\end{Solution}
	\end{Ex}
	
	\begin{Prop}[Общий случай метода введения параметра]
		Пусть есть уравнение $F(x,y,y') = 0$, задающее какую-то поверхность $\sigma=\hr{\hr{x,y,y'}|F\hr{x,y,y'} = 0}$.
		
		Пусть $\begin{cases}
			x = \varphi(u,v),\\
			y=\psi(u,v),\\
			y' = \chi(u,v)
		\end{cases}$ -- параметризация $\sigma$.
	
		Подставим эту параметризацию в основное соотношение $dy = y_x' dx$.
		\[
		\psi_u' du + \psi_v' dv = \chi(u,v) \hr{\varphi_u'du + \varphi_v' dv}.
		\]
		Пусть $v=g(u, C)$ -- решение этого уравнения.
		
		Тогда получаем $\begin{cases}
			x = \varphi(u,v=g(u, C)),\\
			y=\psi(u,v=g(u, C))
		\end{cases}$ -- параметризация решений исходного уравнения.
	\end{Prop}
	\begin{Ex}
		\[xy'-y-\frac{y'}{2}\ln\frac{y'}{2}=0.\]
		\begin{Solution}
			Введем параметризацию 
			\[
			\begin{cases}
				x = u, \\
				y' = v, \\
				y = uv-\frac{v}{2}\ln{v}.
			\end{cases}
			\]
			Тогда подставляя в основное соотношение, получаем
			\[
			\cancel{vdu} + \hr{u-\frac12\ln\frac{v}{2} - \frac12}dv = \cancel{vdu},
			\]
			\[
			\hr{u-\frac12\ln\frac{v}{2} - \frac12}dv = 0,
			\]
			
			При $\hr{u-\frac12\ln\frac{v}{2} - \frac12} = 0$, получаем $v=2e^{2u-1}$. Тогда $y=e^{2x-1}$.
			
			При $dv=0$, получаем $y=cx-\frac{c}{2} \ln\frac{c}{2}$. 
			
			\begin{Note}
				Важно помнить, что это могут быть не все решения уравнения!!! Такой случай уже был рассмотрен в примере \ref{ex_4}.
			\end{Note}
		\end{Solution}
	\end{Ex}
	\section[Задача Коши]{Задача Коши для уравнения, не разрешенного относительно производной}
	\begin{Note}
		Мы уже говорили о решении задачи Коши для нормального уравнения. Однако в силу того, что уравнение $F\hr{x,y,y'} = 0$ задает не одно поле направлений, а целую совокупность, оказывается, что через одну точку могут проходить несколько интегральных кривых, однако под разными углами. Именно поэтому постановка задачи Коши для уравнения, не разрешенного относительно $y'$, требует дополнительного начального условия на $y'$.
	\end{Note}
	\begin{Def}
		Задачей Коши для уравнения $F(x,y,y') = 0$ называется задача нахождения его решения, удовлетворяющего условиям $\begin{cases}
			y(x_0) = y_0,\\
			y'(x_0) = y'_0.
		\end{cases}
	$. (Под $y'_0$ понимается какое-то числовое значение, а не производная. Такое обозначение используется для визуального соответствия.) 
	\end{Def}
	\begin{Prop}
		Чтобы задача Коши могла иметь решение, начальные данные должны быть согласованы, то есть $F(x_0, y_0, y'_0) = 0$.
	\end{Prop}
	\begin{Th}[Существование и единственность решения ЗК для уравнения, не разрешенного относительно производной]
		Пусть $F \in C^1\hr{G}$, где $G \subset \R^3_{x,y,y'}$ -- область. Пусть также точка $(x_0, y_0, y'_0) \in G$ такая, что $F(x_0,y_0, y'_0) =0$, $F_y'(x_0, y_0, y'_0) \neq 0$. Тогда в некоторой окрестности точки $x_0$ существует единственное решение задачи $F(x,y,y') = 0$ при условиях $\begin{cases}
			y(x_0) = y_0,\\
			y'(x_0) = y'_0.
		\end{cases}$
		\begin{Proof}
			TODO: PROOF
		\end{Proof}
	\end{Th}

	\begin{Def}
		Решение $\varphi$ уравнения $F(x, y,y') = 0$ на $\ha{a,b}$ называется особым, если для любой точки $x_0 \in \ha{a,b}$ найдется решение $\psi$ такое, что 
	\end{Def}
	
	
	\part{Системы дифференциальных уравнений}
	\section{}	
	
	\section{Вспомогательные }
	\begin{Def}
		Под нормой вектора $x=\hr{x_1, \dots, x_n} \in \R^n$ будем понимать $|x| = \max\limits_{i=1,\dots,n}|x_i|$.
	\end{Def}
	\begin{Def}
		Нормой матрицы $A = \begin{Vmatrix}
			a_{ij}
		\end{Vmatrix}_{\substack{i=1,\dots,m\\j=1,\dots,n}} \in Mat_{m\times n}(\R)$ будем называть $|A| = \max\limits_{\substack{i=1,\dots,m\\j=1,\dots,n}} |a_{ij}|$.
	\end{Def}
	\begin{Lem}
		Пусть $f \in C(\hs{a,b})$. Тогда 
		\[
		\hm{\int\limits_a^b f(t) dt} \leqslant \int\limits_a^b \hm{f(t)} dt.
		\]
		\begin{Proof}
			\[
			\begin{split}
				\hm{\int\limits_a^b f(t) dt} &= \max\limits_{i=1,\dots,n}\hm{\int\limits_a^b f_i(t) dt} \leqslant \max\limits_{i=1,\dots,n}\int\limits_a^b \hm{f_i(t)} dt \leqslant \\
				&\leqslant \max\limits_{i=1,\dots,n}\int\limits_a^b \hm{f(t)} dt = \int\limits_a^b \hm{f(t)} dt.
			\end{split}
			\]
		\end{Proof}
	\end{Lem}
	\begin{Lem}
		Пусть $A \in Mat_{m\times n}(\R)$ и $B \in Mat_{n\times k}(\R)$. Тогда $\hm{A\cdot B} \leqslant n \cdot \hm{A} \cdot \hm{B}$.
		\begin{Proof}
			Вспомним, как вводилось определение произведения матриц: $\hs{A\cdot B}_{i,j} = \sum\limits_{l=1}^n \hs{A}_{i,l} \cdot \hs{B}_{l,j}$. Тогда перейдем к нормам
			\[
			\begin{split}
				\hm{\hs{A\cdot B}_{i,j}} = \hm{\sum\limits_{l=1}^n \hs{A}_{i,l} \cdot \hs{B}_{l,j}} \leqslant \sum\limits_{l=1}^n \hm{\hs{A}_{i,l}} \cdot \hm{\hs{B}_{l,j}} \leqslant \sum\limits_{l=1}^n \hm{A} \cdot \hm{B} = n \cdot \hm{A}\cdot\hm{B}.
			\end{split}
			\]
		\end{Proof}
	\end{Lem}
	\begin{Def}
		Функция $f: D \to \R^n$ удовлетворяет условию Липшица на множестве $D$, если $\exists L: \quad \forall r_1, r_2 \in D \implies |f(x_2) - f(x_1)| \leqslant L |r_2-r_1|$. И пишут $f\in Lip(D)$.
	\end{Def}
	\begin{Ex}
		Рассмотрим функцию $f(x) = \sqrt{x}$ на отрезке $D=\hs{\frac12, 1}$.
		\[
		\begin{split}
			\hm{f(r_2) - f(r_1)} = \hm{f'(\xi)} \hm{r_2-r_1} \leqslant \underbrace{\hm{\max\limits_{\hs{\frac12,1}}f'(\xi)}}_{L} \hm{r_2-r_1}.
		\end{split}
		\]
		Таким образом, функция $f(x) = \sqrt{x}$ удовлетворяет условию Липшица на отрезке $D=\hs{\frac12,1}$.
	\end{Ex}
	\begin{Prop}
		Этот пример наводит на идею того, что всегда, когда производная ограничена, мы можем найти константу Липшица как $L~=~\hm{\max\limits_{\hs{\frac12,1}}f'(\xi)}$.
	\end{Prop}
	\begin{Prop}
		На самом деле можно показать, что $C^1\hs{a,b} \subset Lip\hs{a,b} \subset C\hs{a,b}$.
	\end{Prop}
	
	\begin{Ex}
		Рассмотрим все ту же функцию $f(x) = \sqrt{x}$, но на множестве $D=\hs{0,1}$. Покажем, что она не Липшицива.
		\begin{Proof}
			Пусть $f\in Lip D$, то есть нашлось такое $L$, что
			\[
			|\sqrt{x_2} - \sqrt{x_1}| \leqslant L |r_2-r_1|.
			\]
			Возьмем в качестве точки $x_1$ точку $0$, а точку $x_2$ устремим к нулю
			\[
			\sqrt{x_2} \leqslant L \hm{x_2} \implies \infty \underset{x_2\to0}{\leftarrow} \frac{1}{\sqrt{x_2}} \leqslant L \underset{x_2\to0}{\rightarrow} L,
			\]
			что невозможно, а значит исходное предположение неверно и функция не Липшицива.
		\end{Proof}
	\end{Ex}
	\begin{Note}
		Однако понятно, что, отступив на чуть-чуть от нуля в множестве $D$, функция сразу станет Липшицевой. Именно поэтому появляется понятие локальной Липшицевости.
	\end{Note}
	\begin{Def}
		$f: D \to \R^n$ удовлетворяет условию Липшица локально на множестве $D$, если $\forall r \in D \implies \exists U(r): \quad f \in Lip(D\cap U)$. И пишут $f\in Lip_{loc} D$.
	\end{Def}
	\begin{Ex}
		Несложно показать, что $f(x) =\sqrt{x}$ на множестве $D=\hrs{0,1}$ удовлетворяет условию локальной Липшицевости, но не глобальной.
	\end{Ex}

	\begin{Def}
		$f: D \to \R^n_{t,r}$ удовлетворяет условию Липшица по $r$ на множестве $D$, если $\exists L: \quad \forall (t, r_1), (t,r_2) \in D \implies |f(t, x_2) - f(t,x_1)| \leqslant L |r_2-r_1|$. И пишут $f\in Lip_r D$.
	\end{Def}

	\begin{Def}
		$f: D \to \R^n_{t,r}$ удовлетворяет условию Липшица по $r$ локально на множестве $D$, если $\forall (t,r) \in D \implies \exists U((t,r)): \quad f \in Lip_r(D\cap U)$. И пишут $f\in Lip_{r,loc} D$.
	\end{Def}

	\begin{Ex}
		Рассмотрим $f(t,r) = \frac1t + \frac1r$ на множестве $D = \hr{0, +\infty} \times \hs{\frac12, 1}$.
		
		Посмотрим на разность значений в разных точках $\hr{t_1, r_1}$, $\hr{t_2, r_2}$:
		\[
		\hm{f\hr{t_2, r_2}-f\hr{t_1, r_1}} = \hm{\frac1{t_2} - \frac1{t_1} + \frac1{r_2} - \frac1{r_1}}
		\]
		Понятно, что при очень маленьких $t_1, t_2$ разность оказывается очень большой, а  значит мы ничем не ограничим сверху. То есть глобальное условие Липшица не выполнено.
		
		Однако локально
		\[
		\begin{split}
		\hm{\frac1{t_2} - \frac1{t_1} + \frac1{r_2} - \frac1{r_1}} &\leqslant \hm{\frac{t_1-t_2}{t_1t_2}} + \hm{\frac{r_2-r_1}{r_2r_1}} \leqslant\\&\leqslant \mu_1 \hm{t_2-t_1} + \mu_2 \hm{r_2-r_1} \leqslant \underbrace{\max\ha{\mu_1, \mu_2} \cdot 2}_{L} \hm{(t_1,r_1)- (t_2,r_2)}
		\end{split}
		\]
		она удовлетворяет условию Липшица.
	\end{Ex}

	\begin{Ex}
		Рассмотрим $f(t,r) = \sqrt{t} \sqrt{r}$ на множестве $\hsr{0, +\infty} \times \hr{0,1}$.
		
		Локальному условию Липшица она не удовлетворяет, рассматривая точку 0.
		
		Однако по $r$ она локально Липшицева:
		\[
		\hm{f(t,r_2) - f(t,r_1)} = \hm{\sqrt{r_2} - \sqrt{r_1}} \leqslant L \hm{r_2-r_1},
		\]
		где в качестве $L$ возьмем максимум производной корня. 
	\end{Ex}

	\begin{Lem}[Достаточное условие для локальной Липшицевости по $r$]
		Пусть $G \subset \R^{n+1}_{t,r}$ -- область, $f: \; G \to \R^m$. А также $f'_r \in Mat_{m,n}\hr{C(G)}$. Тогда $f\in Lip_{r,loc}(G)$.
		
		Кроме того, если $K$ -- выпуклый компакт, а $M = \max\limits_K \hm{f'_r}$, то $f\in Lip_rK$ с константой Липшица $L=nM$.
		
		\begin{Proof}
			Пусть $K$ -- выпуклый компакт.
			\begin{figure}[h!]
				\centering
				\begin{tikzpicture}
					\draw[->] (-1,0) -- (3,0) node[right]{$t$};
					\draw[->] (0, -1) -- (0,3) node[above]{$r$};
					\draw[orange] (1,2) circle(2);
					\draw[orange] (3,3) node[right]{$K$};
					\draw[blue] (0,1) circle(1pt) node[left]{$r_1$};
					\draw[blue] (0,2) circle(1pt) node[left]{$r_2$};
					\draw[blue] (1,0) circle(1pt) node[below]{$t$};
					\draw[blue, line width=2pt] (1,1) -- (1,2);
					\draw[blue, opacity=0.8, dotted] (1,1) -- (0,1);
					\draw[blue, opacity=0.8, dotted] (1,2) -- (0,2);
					\draw[blue, opacity=0.8, dotted] (1,0) -- (1,1);
					
				\end{tikzpicture}
			\end{figure}
		
		Рассмотрим разность значений:
		\[
		\hm{f(t,r_2) - f(t,r_1)} = \Delta.
		\]
		Так как $K$ -- выпуклое, то отрезок тоже принадлежит $K$.\\
		Рассмотрим функцию $g(s) = f(t, r_1 + s(r_2-r_1))$, определенную на $\hs{0,1}$. Заметим, что $g$ непрерывная, как композиция сужения $f$ на $r$ ($h(r) = f(t,r)$) и линейной там же ($r_1 + s(r_2-r_1)$).\\
		Тогда по интегральной теореме Лагранжа
		\[
		\begin{split}
		\Delta &= \hm{g(1) - g(0)} = \hm{\int\limits_0^1 g'(s) ds} = \hm{\int\limits_0^1 h'(r_1 + s(r_2-r_1))\cdot(r_1 + s(r_2-r_1))' ds} =\\
		&= \hm{\int\limits_0^1 f'_r (r_1 + s(r_2-r_1)) \cdot (r_2-r_1) ds} \leqslant \int\limits_0^1 n \cdot \hm{f'_r} \cdot \hm{r_2-r_1} ds \leqslant\\
		&\leqslant n \cdot \underbrace{\max\limits_K \hm{f'_r}}_{M} \cdot \hm{r_2-r_1}. 
		\end{split}
		\]
		Таким образом, Лишицива константа равна $n\cdot M$.
		
		Рассмотрим область $G$. Вокруг каждой точки можем рассмотреть брус $\Pi$, который является компактом, а значит на нем у нас есть глобальная Липшицивость. То есть мы для каждой точки нашли окрестность, в которой есть глобальная Липшицивость, а значит по определению получили локальную Липшицивость на $G$.
		\end{Proof}
	\end{Lem}

	\begin{Lem}[Достаточное условие для Липшицивости по $r$]
		Пусть $G \subset \R^{n+1}_{t,r}$ -- область, $f: \; G \to \R^m$, $f \in Lip_{r,loc} K$, где $K\in G$ -- компакт. 
		
		Тогда $f$ глобально Липшицива на $K$.
		
		\begin{Proof}
			Пусть $f\notin Lip_r K$, то есть
			\[
			\forall L \quad \exists (t,r_2), (t,r_1) \in K: \; \hm{f(t,r_2) - f(t, r_1)} > L \hm{r_2-r_1}.
			\]
			Найдем для каждого натурального числа $L$ пару таких точек $(t_n, r_n), (t_n, \tilde{r_n})$. Так как $K$ компакт в $\R^{n+1}$, то оно секвенциальный компакт, а значит можно выделить сходящиеся подпоследовательности.
			
			Пусть для первой последовательности есть $\hc{(t_{k_s}, r_{k_s})}_{s=1}^{\infty}: \quad (t_{k_s}, r_{k_s}) \to (t,r)$. Выберем во второй последовательности с теми же номерами сходящуюся подпоследовательность $\hc{(t_{k_{s_l}}, \tilde{r}_{k_{s_l}})}_{l=1}^{\infty}: \quad (t_{k_{s_l}}, \tilde{r}_{k_{s_l}}) \to (t,\tilde{r})$. 
			
			\begin{enumerate}
				\item Пусть $r=\tilde{r}$.
				
				Так как $f \in Lip_{r,loc} K$, то есть на окрестности $U(t,r)$ $f \in Lip_{r} U$. Пусть условие Липшица выполнено с константой $L$, то есть 
				\[
				\forall (\tau, \rho_1), (\tau,\rho_2) \in D \implies |f(\tau, \rho_2) - f(\tau,\rho_1)| \leqslant L |\rho_2-\rho_1|.
				\]
				Так как начиная с какого-то номера все элементы наших последовательностей лежат в окрестности $U(t,r)$, то, выбирая $l$ так, чтобы $L_{s_l} > L$, получаем противоречие нелипшицивости $K$, но липшицивости на $U$.
				\item Пусть $r\neq \tilde{r}$.
				
				\[
				\hm{f(t_{k_{s_l}},r_{k_{s_l}}) - f(t_{k_{s_l}}, \tilde{r}_{k_{s_l}})} > L_{s_l} \hm{r_{k_{s_l}}-\tilde{r}_{k_{s_l}}}.
				\]
				Переходя к пределу при $l \to \infty$, получаем
				\[
				\hm{f(t,r)- f(t,\tilde{r})} \geqslant \infty,
				\]
				что невозможно. Снова пришли к противоречию. 
			\end{enumerate}
			 А значит исходное предположение было неверным и на самом деле $f~\in~Lip_r K$.
		\end{Proof} 
	\end{Lem}
	
	\section[Существование и единственность]{Теоремы о существовании и единственности}
	\begin{Def}
		Функция $\varphi: E=\ha{a,b} \to \R^n$ --- решение интегрального уравнения $r(t) = r_0 + \int\limits_{t_0}^t f(\tau, r(\tau))d\tau$, если
		\begin{enumerate}
			\item Она непрерывна: $\varphi \in C(E)$,
			\item Она обращает уравнение в тождество $\varphi(t) \equiv r_0 + \int\limits_{t_0}^t f(\tau, \varphi(\tau))d\tau$.
		\end{enumerate}
	\end{Def}
	\begin{Lem}[О равносильном интегральном уравнении]
		Пусть $G \subset \R^{n+1}_{t,r}$ -- область, $f \in C(G \to \R^n)$, $\hr{t_0, r_0} \in G$.
		Тогда $\varphi$ -- решение задачи Коши $r'=f(t,r)$, $r(t_0)=r_0$ на $E=\ha{a,b}$ тогда и только тогда, когда $\varphi$ -- решение интегрального уравнения.
		\begin{Proof}
			"Необходимость":\\
			Так как $\varphi$ -- решение задачи Коши, то $\varphi \in C^1(E)$, а значит первый пункт определения решения интегрального уравнения выполнен. Второй же получаем просто проинтегрировав дифференциальное уравнение.
			"Достаточность":\\
			Так как интеграл от непрерывной функции -- непрерывно дифференцируем, то первый пункт определения решения задачи Коши получили. А второй получается дифференцируемостью второго пункта определения решения интегрального уравнения. 
		\end{Proof}
	\end{Lem}

	\begin{Lem}
		Пусть $G \subset \R^{n+1}_{t,r}$ -- область, $f \in C(G \to \R^n)$, $\hr{t_0, r_0} \in G$. Пусть также $\varphi_+, \varphi_-$ -- решения задачи Коши $r'=f(t,r)$, $r(t_0)=r_0$ на $\hsr{t_0,b}$ и $\hrs{a,t_0}$ соответственно.
		
		Тогда $\varphi(t) = \begin{cases}
			\varphi_-(t), \quad t\in \hrs{a,t_0} \\
			\varphi_+(t), \quad t\in \hsr{t_0,b} \\
		\end{cases}$ -- решение этой же задачи Коши на интервале $\hr{a,b}$.
	\begin{Proof}
		Очевидно, что функция остается непрерывно дифференцируемой и обращает уравнение в тождество.
	\end{Proof}
	\end{Lem}
	 \begin{Lem}[Gronwall]
	 	Пусть $\varphi \in C(E)$, где $E=\ha{a,b}$. Пусть также $\lambda, \mu \geqslant 0$ и $\forall \, t \in E \quad 0 \leqslant \varphi(t) \leqslant \lambda + \mu \hm{\int\limits_{t_0}^t \varphi(\tau)d\tau}$. 
	 	
	 	Тогда $\varphi(t) \leqslant \lambda e^{\mu\hm{t-t_0}}$.
	 	\begin{Proof}
	 		Заметим, что в правой части цепочки неравенств на самом деле стоит решение задачи Коши для линейного дифференциального уравнения. 
	 		
	 		Пусть $t\geqslant t_0$.
	 		\begin{enumerate}
	 			\item Пусть $\lambda>0$. Обозначим $v(t) = \lambda + \mu \hm{\int\limits_{t_0}^t \varphi(\tau)d\tau}$.
	 			
	 			Тогда $v'(t) = \mu \varphi(t) \leqslant \mu \cdot v(t)$.\\
	 			Так как $\lambda>0$, то и $v>0$. Значит можем поделить на $v$. 
	 			\[
	 			\frac{v'(t)}{v(t)} \leqslant \mu,
	 			\]
	 			\[
	 			\int\limits_{t_0}^t \frac{v'(\tau)}{v(\tau)} d \tau \leqslant \int\limits_{t_0}^t\mu d\tau,
	 			\]
	 			\[
	 			\ln \frac{v(t)}{v(t_0)} \leqslant \mu \hr{t-t_0},
	 			\]
	 			\[
	 			v(t) \leqslant \underbrace{v(t_0)}_{\lambda} e^{\mu\hr{t-t_0}}.
	 			\]
	 			Таким образом, $\varphi(t) \leqslant v(t) \leqslant\lambda e^{\mu\hr{t-t_0}}$.
	 			\item Пусть $\lambda=0$.\\
	 			\[
	 			\varphi(t) \leqslant \mu \int\limits_{t_0}^t \varphi(\tau)d\tau < \underbrace{\delta}_{>0} + \mu \int\limits_{t_0}^t \varphi(\tau)d\tau.
	 			\]
	 			Устремим $\delta$ к нулю для каждого $t$: $\varphi(t) \leqslant 0$, что и хотелось доказать.
	 		\end{enumerate}
 			При $t<t_0$ сделаем замену $\varphi(t) = \psi(2t_0 - t)$.
 			\[
 			\psi(2t_0-t) \leqslant \lambda + \mu \int\limits_{t_0}^{2t_0-t} \psi(s) ds
 			\]
 			По доказанному (так как $2t_0-t>t_0$) получаем $\varphi(t) = \psi(2t_0-t) \leqslant \lambda e^{\mu \hr{2t_0-t-t_0}}$.
	 	\end{Proof}
	 \end{Lem}
 
 	\begin{Def}
 		Пусть $G \subset \R^{n+1}_{t,r}$ -- область, $f \in C(G \to \R^n)$, $\hr{t_0, r_0} \in G$. Пусть $\Pi= \hc{|t-t_0|\leqslant a, |r-r_0| \leqslant b}$ -- брус с центром в точке  $\hr{t_0, r_0}$, вписанный в данную область (такой есть в силу открытости области).
 		
 		Пусть $\|f\| = \max\limits_{\Pi} |f|$. Тогда отрезок $\hs{t_0-h, t_0+h}$, где $h=\min \hc{a, \frac{b}{\|f\|}}$ -- называется отрезком Пеано, соответствующим $t_0, r_0$.
 	\end{Def}
 	\begin{Note}
 		Рассмотрим, что имеется в виду, на простом двумерном примере $f:\; \R^2 \to \R$ бруса. Для простоты рассмотрим случай бруса с центром в начале координат.
 		Пусть есть какое-то решение $\varphi$, проходящее внутри бруса. Тогда 
 		\[
 		\hm{\varphi(t)} = \hm{\int_0^t \varphi'(t) dt} \leqslant \int_0^t |\varphi'(t)| dt \leqslant \int_0^t \|f\| dt = \|f\| t.
 		\]
 		То есть мы получили, что наше решение ограничено внутри бруса двумя лучами. Кардинально появляется два случая: лучи пересекают горизонтальное ребро бруса или вертикальное (см. Рис. \ref{Peano}). В первом случае мы можем уверенно утверждать, что наше решение лежит внутри бруса на отрезке до пересечения луча с брусом. А во втором --- на всем отрезке бруса. Вот эти отрезки и называются отрезками Пеано $\hs{0, h}$, где в первом случае $h=\frac{b}{\|f\|}$, а во втором -- $h=a$.
 		\begin{figure}
 			\centering
 			\begin{subfigure}{0.45\linewidth}
 				\begin{tikzpicture}
 					\draw[gray, ->] (-2.5,0) -- (2.5,0) node[right]{$t$};
 					\draw[gray, ->] (0,-2.5) -- (0,2.5) node[above]{$r$};
 					\draw (-2,-2) rectangle (2,2);
 					\draw (2,1) node[right] {$\Pi$};
 					\draw (2,0) node[below right] {$a$};
 					\draw (0,2) node[above left] {$b$};
 					\draw[purple] (0,0) -- (1,2);
 					\draw[purple] (0,0) -- (1,-2);
 					\draw[dotted, orange] (1,2) -- (1,0) node[below]{$h$} -- (1,-2);
 					\draw[line width=1.5pt, orange] (0,0) -- (1,0);
 					\draw[line width=2pt, blue] (0,0) ..controls (1,0.5) and (1,1) .. (1,1);
 				\end{tikzpicture}
 			\end{subfigure}
 			\begin{subfigure}{0.45\linewidth}
 			\begin{tikzpicture}
					\draw[gray, ->] (-2.5,0) -- (2.5,0) node[right]{$t$};
					\draw[gray, ->] (0,-2.5) -- (0,2.5) node[above]{$r$};
 				\draw (-2,-2) rectangle(2,2);
 				\draw (2,1) node[right] {$\Pi$};
 				\draw (2,0) node[below right] {$a$};
 				\draw (0,2) node[above left] {$b$};
 				\draw[purple] (0,0) -- (2.5, 2);
 				\draw[purple](0,0) -- (2.5,-2);
 				\draw[orange] (2,0) node[below left]{$h$};
 				 \draw[line width=1.5pt, orange] (0,0) -- (2,0);
 				\draw[line width=2pt, blue] (0,0) ..controls (1,0) and (1,0.4) .. (2,0.5);
 			\end{tikzpicture}
 		\end{subfigure}
 		\caption{Иллюстрация к определению отрезка Пеано} \label{Peano}
 		\end{figure}
 	\end{Note}
 
	\begin{Th}[Пеано о существовании решения]
		Пусть $G \subset \R^{n+1}_{t,r}$ -- область, $f \in C(G \to \R^n)$, $\hr{t_0, r_0} \in G$. 
		
		Тогда задача Коши имеет решение на отрезке Пеано.
		\begin{Note}
			Без доказательства.
		\end{Note}
	\end{Th}
	\begin{Th}[Пикара о существовании и единственности решения]
		Пусть $G \subset \R^{n+1}_{t,r}$ -- область, $f \in C(G \to \R^n) \cap Lip_{r,loc}$, $\hr{t_0, r_0} \in G$.
		
		Тогда \begin{enumerate}
			\item На отрезке Пеано существует решение задачи Коши,
			\item На любом интервале $\hr{a,b}$ решение задачи Коши единственно.
		\end{enumerate}
	\begin{Proof}
		Не умоляя общности, рассмотрим в качестве $\hr{t_0,r_0}$ точку начала координат. 
		Будем искать решение при $t\in \hs{0,h}$, где $h=\min \hc{a, \frac{b}{\|f\|}}$ из определения отрезка Пеано.
		
		Рассмотрим последовательность, заданную реккурентно 
		\[
		\begin{split}
			&\varphi_0(t) = 0,\\
			&\varphi_m(t) = \int\limits_0^t f(\tau, \varphi_{m-1}(\tau))d\tau.
		\end{split}
		\]
		
		\begin{Note}
			Укажем план нашего доказательства:
			\begin{enumerate}
				\item Докажем, что последовательность определена корректна, то есть $\varphi_m \in C\hs{0,h}$ и $\hm{\varphi_m(t)} \leqslant \|f\| t$,
				\item Докажем равномерную сходимость последовательности, то есть $\exists \varphi: \quad \varphi_m \underset{m\to\infty}{\rightrightarrows} \varphi$,
				\item Докажем, что полученное $\varphi$ является решением интегрального уравнения, связанного с задачей Коши,
				\item Докажем единственность.
			\end{enumerate}
		\end{Note}
		$\bullet$
		\begin{enumerate}
			\item Докажем методом математической индукции:\\
			При $m=0$: $\varphi_0$ определена на $\hs{0,h}$.\\
			Пусть $\varphi_m \in C(\hs{0,h})$ и $\hm{\varphi_m(t)} \leqslant \|f\|t$.\\
			Рассмотрим $\varphi_{m+1}(t) = \int\limits_0^t f(\tau, \varphi_m(\tau))d\tau$. Так как $t\leqslant h \leqslant \frac{b}{\|f\|}$, то $\hm{\varphi_m} \leqslant b$. Тогда $f(\tau, \varphi_m(\tau))$  есть композиция непрерывных функций, а значит она интегрируема и функция $\varphi_{m+1}$ задана корректно на $\hs{0,h}$, причем к тому же она непрерывна. 
			\[
			\begin{split}
				\hm{\varphi_{m+1}} \leqslant \hm{\int\limits_0^t f(\tau, \varphi_m(\tau))d\tau} \leqslant \int\limits_0^t \hm{f(\tau, \varphi_m(\tau))}d\tau \leqslant \|f\| \int\limits_0^td\tau = \|f\| t.
			\end{split}
			\]
			Таким образом, индукционный переход выполняется, а значит наша последовательность задана корректно для любого $n\in\N$.
			\item Докажем, что $\hc{\varphi_n}_{n\in\N}$ -- фундаментальная, то есть 
			\[
			\forall \varepsilon \quad \exists n_0: \quad \forall m \geqslant n_0, k\in \N \implies \|\varphi_m - \varphi_{m+k}\| < \varepsilon.
			\]
			На самом деле будем доказывать более сильное утверждение, а именно
			\[
			\forall t\in\hs{0,h} \quad \forall m\in \Z_+, k \in \N \quad \exists L: \quad \hm{\varphi_m(t) - \varphi_{m+k}(t)}\leqslant \frac{\|f\| L^m \cdot t^{m+1}}{(m+1)!}.
			\]
			Воспользуемся методом математической индукции по $m$.\\
			При $m=0$: 
			\[
			\hm{\varphi_0(t) - \varphi_k(t)} = \hm{\int\limits_0^t f(\tau, \varphi_{k-1}(t))d\tau} \leqslant t \cdot \|f\|.
			\]
			Пусть при некотором $m$ утверждение верно, докажем для $m+1$
			\[
			\begin{split}
			\hm{\varphi_{m+1}(t) - \varphi_{m+1+k}(t)} &= \hm{\int\limits_0^t f(\tau, \varphi_{m}(t))d\tau - \int\limits_0^t f(\tau, \varphi_{m+k}(\tau))d\tau} \leqslant \\
			&\leqslant \int\limits_0^t \hm{f(\tau, \varphi_{m}(t))d\tau - f(\tau, \varphi_{m+k}(\tau))d\tau} \boxed{\leqslant}
			\end{split} 
			\]
			Так как у нас есть локальная Липшицевость, то можем найти на компакте, а именно на нашем брусе, $L$, что
			\[
			\begin{split}
			& \boxed{\leqslant} \int\limits_0^t L \cdot \hm{\varphi_m(\tau) - \varphi_{m+k}(\tau)}d\tau \leqslant \frac{\|f\|L^{m+1}}{(m+1)!}\int\limits_0^t\tau^{m+1}d\tau = \\
			&= \frac{\|f\|L^{m+1}}{(m+2)!}t^{m+2}.
			\end{split}
			\]
			Таким образом, по Критерию Коши, есть $\varphi\in C(\hs{0,h})$, что $\varphi_m \underset{m\to\infty}{\rightrightarrows} \varphi$.
			\item Рассмотрим интегральное уравнение, равносильное задаче Коши. 
			\[
			\varphi_{m+1} = \int\limits_0^t f(\tau, \varphi_m(\tau))d\tau.
			\]
			при $m\to\infty$
			\[
			\varphi(t) = \lim\limits_{m\to\infty} \int\limits_0^t f(\tau, \varphi_m(\tau))d\tau.
			\]
			Рассмотрим 
			\[
			\begin{split}
				\hm{\int\limits_0^t f(\tau, \varphi_m(\tau))d\tau 0 \int\limits_0^t f(\tau, \varphi(\tau))d\tau} &\leqslant \int\limits_0^t \hm{f(\tau, \varphi_m(\tau)) - f(\tau, \varphi(\tau))}d\tau \leqslant \\
				& \leqslant L\int\limits_0^t \hm{\varphi_m(\tau) - \varphi(\tau)}d\tau \leqslant\\
				&\leqslant L \cdot \|\varphi_m - \varphi\| \cdot h \to 0.
			\end{split}
			\]
			Таким образом, $\varphi(t) = \int\limits_0^t f(\tau, \varphi(\tau))d\tau$, а значит $\varphi$ -- решение интегрального уравнения, а тогда и задачи Коши.
			\item Пусть есть два разных решения $\psi_1, \psi_2$ задачи Коши на отрезке $\hs{a,b}$.
			Рассмотрим 
			\[
			\begin{split}
			\hm{\psi_1(t) - \psi_2(t)} &= \hm{\int\limits_0^t f(\tau, \psi_1(\tau))d\tau - \int\limits_0^t f(\tau, \psi_2(\tau))d\tau} \leqslant \\
			&\leqslant \int\limits_0^t \hm{f(\tau, \psi_1(\tau))d\tau - f(\tau, \psi_2(\tau))}d\tau \boxed{\leqslant}
			\end{split}
			\]
			Рассмотрим графики $\gamma_1 = \left.\psi_1\right|){\hs{\alpha, \beta}}$ и $\gamma_2 = \left.\psi_2\right|){\hs{\alpha, \beta}}$. Тогда $\gamma_1 \cap \gamma_2$ -- компакт. А значит из локальной Липшицевости на компакте можем найти константу $\mu$, для которой
			\[
			\begin{split}
				&\boxed{\leqslant} \int\limits_0^t \mu \hm{\psi_1(\tau) - \psi_2(\tau)}d\tau.
			\end{split}
			\]
			А значит получили по лемме Gronwall $\hm{\psi_1(t) - \psi_2(t)} \leqslant 0$, то есть на самом деле $\hm{\psi_1(t) - \psi_2(t)} \equiv 0$ на $\hs{\alpha, \beta}$. Так как это утверждение выполнено для любых $\alpha, \beta$ из интервала $\hr{a,b}$, то на самом деле  $\hm{\psi_1(t) - \psi_2(t)} \equiv 0$ на $\hr{a, b}$. 
			
			Таким образом, два решения совпали.
		\end{enumerate}
	\end{Proof}
	\end{Th}
	\begin{Cor}[Теорема Пикара с простыми условиями]
		Пусть $G \subset \R^{n+1}_{t,r}$ -- область, $\hr{t_0, r_0} \in G$, $f \in C(G \to \R^n)$, причем $f'_r \in Mat_n\hr{C(G)}$.
		Тогда \begin{enumerate}
			\item На отрезке Пеано существует решение задачи Коши,
			\item На любом интервале $\hr{a,b}$ решение задачи Коши единственно.
		\end{enumerate}
		
		А также \[
		\|\varphi-\varphi_m\| \leqslant \frac{\|f\| \cdot \hr{n\|f\|}^n \cdot h^{n+1}}{\hr{n+1}!}
		\]
		\begin{Proof}
			Из достаточного условия локальной Липшицевости прилетают все ограничения.
			А вторая часть из доказательства, устремляя $k$ к бесконечности.
		\end{Proof}
	\end{Cor}
	
	\section{Продолжение решений}
	\begin{Note}
		Теорема Пикара дает представление только о решении на отрезке Пеано, однако этот отрезок может оказаться очень маленьким и не давать необходимого понимания о дифференциальном уравнении. Поэтому хочется расширять решение за границы отрезка Пеано, причем понимая до куда мы это действительно можем сделать.
	\end{Note}
	\begin{Ex}
		\[
		x' = 1+x^2, \qquad x(0) = 0.
		\]
		\begin{Solution}
			\begin{figure}[h!]
				\centering
				\begin{tikzpicture}[scale=0.5]
					\draw[->] (-5,0) -- (5,0);
					\draw[->] (0,-5) -- (0,5);
					\draw[domain=-1.37:1.37, thick, green] plot (\x, {tan(\x r)});
					\draw[domain=-pi/4:pi/4, thick, red] plot (\x, {tan(\x r)});
					\draw[dashed, orange] (-1.57,-5) -- (-1.57,5);
					\draw[dashed, orange] (1.57,-5) -- (1.57, 5);
					\draw[dashed, blue] (pi/4, -5) -- (pi/4, 5);
					\draw[dashed, blue] (-pi/4, -5) -- (-pi/4, 5);
					
				\end{tikzpicture}
			\end{figure}
			Очевидно, что решение уравнения -- это $x=\tg t$ на отрезке $\hs{-\frac{\pi}{4}, \frac{\pi}{4}}$. Однако вполне очевидно, что решение можно продолжить до интервала $\hr{-\frac{\pi}{2}, \frac{\pi}{2}}$. Причем дальше продолжать уже не получится, то есть это максимальное решение.
		\end{Solution}
	\end{Ex}
	\begin{Def}
		Решение $\varphi$ называется максимальным решением системы, если не существует другого решения $\psi$ такого, что $\varphi$ является сужением $\psi$.
	\end{Def}
	\begin{Th}[критерий продолжимости]
		Пусть $f\in C\hr{G\to \R^n}$, $G\subset \R_{t,r}^{n+1}$ -- область, а $\varphi$ -- решение на $\hr{a,b}$. Тогда $\varphi$ продлолжимо на $\hr{a,c}$, где $c>b$ тогда и только тогда, когда $\hr{b,\varphi(b-0)} \in G$.
		\begin{Proof}
			Так как $\varphi$ непрерывно, то $\varphi(b-0) = \varphi(d)$. Тогда, так как каждая интегральная кривая должна лежать в $G$, то и точка $(d, \varphi(b))$ лежит в $G$.
			
			Обратно. Решим задачу Коши с той же системой, но с начальным условием, что в точке $b$ значение равно $\varphi(b-0)$. Тогда по теореме Пеано, есть отрезок $\hs{b,b+h}$ (на самом деле и левая часть отрезка тоже есть, но нам она неважна), на котором существует решение. Тогда по лемме о стыковке решений получим решение исходной задачи Коши на $\hrs{a,b+h}$, что является продолжением.
		\end{Proof}
	\end{Th}
	
	\begin{Cor}
		Пусть $f\in C\hr{G\to \R^n}$, $G\subset \R_{t,r}^{n+1}$ -- область, а $\varphi$ -- максимальное решение задачи Коши. Тогда область решения -- обязательно интервал.
		\begin{Proof}
			Пусть решение -- не интервал, а, например, $\hrs{a,b}$. Тогда точка $b$ лежит в $G$, а значит по критерию можем продолжить решение.
		\end{Proof}
	\end{Cor}

	\begin{Th}[О существовании единственного максимального решения]
		Пусть $f\in C\hr{G\to \R^n} \cap Lip_{r, loc}$, $G\subset \R_{t,r}^{n+1}$ -- область. 
		Тогда 
		\begin{enumerate}
			\item Существует максимальное решение $\varphi$ задачи Коши
			\[
			r'=f(t,r), \qquad r(t_0) = r_0.
			\]
			\item Любое другое решение этой задаче Коши является сужением $\varphi$.
		\end{enumerate}
	\begin{Proof}
		Рассмотрим множество $s$ всех решений этой задачи Коши (заданных на любых промежутках). 
		Пусть $a = \inf\limits_{\psi\in s}\inf \dom \psi$, $b = \sup\limits_{\psi\in s}\sup \dom \psi$, то есть это максимальные из левых и правых границ. 
		
		Рассмотрим точку $t\in \hsr{t_0,b}$. Из опрделения супремума найдется $\psi:\; \sup \dom \psi > t$. Тогда определим в этой точке $\varphi(t) = \psi(t)$. Таким образом, в каждой точке $t\in \hsr{t_0, b}$ мы задали какое-то значение функции $\varphi(t)$. 
		
		\begin{Note}
			Однако может оказаться, что таких функций $\psi$ несколько. Тогда непонятно, каким образом выбирать значение для $\varphi$. Однако по второму пункту теоремы Пикара мы знаем, что на пересечении областей определения этих решений они совпадают. А точка $t$ точно лежит на этом пересечении, а значит все значения этих $\psi_i$ в точке $t$ одинаковы.
		\end{Note}
	
		Аналогично задаем $\varphi$ на $\hrs{a,t_0}$. 
		
		Тогда, так как в точке $t \in \hr{a,b}$ и ее какой-то окрестности $\varphi \equiv \psi$, то в силу того, что $\psi $ --  решение, оказывается, что $\varphi$ -- непрерывно дифференцируема в точке $t$ и при этом обращает уравнение в тождество. А значит $\varphi$ -- решение.
		
		Почему максимальное решение? Очевидно, что все решения из $s$ являются сужением $\varphi$, так как по второму пункту теоремы Пикара два решения $\varphi$ и $\psi$ совпадают на пересечении областей определения, которое на самом деле есть область $\psi$, а это пересечение есть А значит, по определению, $\varphi$ -- максимальное решение.
	\end{Proof}
	\end{Th}
	\begin{Th}[О выходе интегральной кривой за пределы любого компакта]
		Пусть $f\in C\hr{G\to \R^n} \cap Lip_{r, loc}$, $G\subset \R_{t,r}^{n+1}$ -- область, $\varphi$ -- максимальное решение, заданное на $\hr{a,b}$, $K \subset G$ -- компакт. Тогда существует $\Delta$, что $\forall t\in\hr{a, a+\Delta}\cup\hr{b-\Delta, b} \quad \hr{t,\varphi(t)} \notin K$ (то есть фактически любое решение точно выходит из компакта).
		\begin{Proof}
			\begin{Prop}
				Расстояние $\rho = \rho(K, \partial G) > 0$.
			\end{Prop}
			\begin{Prop}
				Пусть $\Pi(t',r') = \hc{\hr{t,r}\in G | \|\hr{t',r'} - \hr{t,r}\|\leqslant \frac{\rho}{2}}$ и $K_{\rho} = \underset{\hr{t',r'}\in K}{\cup} \Pi(t',r')$. Тогда $K_{\rho}$ -- компакт, причем $K_{\rho} \subset G$.
			\end{Prop}
		\end{Proof}
	\end{Th}

	\part{Линейные системы дифференциальных уравнений}
	
	\section{}
	
	\section{}
	\begin{Th}
		Пусть $P\in Mat_n\hr{C\hr{a,b}}$. Тогда общее решение линейной однородной системы $r' = P(t) r$ есть $n$-мерное линейное пространство.
		\begin{Proof}
			Линейность этого пространства очевидна: сумма лежит в нем, умножение на скаляр -- тоже.
			
			Решим $n$ задач Коши для этой систем с условиями: 
			\[
			r(t_0) = \begin{bmatrix}
				1\\0\\\vdots\\0
			\end{bmatrix},
		r(t_0) = \begin{bmatrix}
			0\\1\\\vdots\\0
		\end{bmatrix},\dots r(t_0) = \begin{bmatrix}
		0\\0\\\vdots\\1
	\end{bmatrix}.
			\] 
			По теореме о существовании решения, существуют $\varphi_1, \varphi_2, \dots, \varphi_n$ -- решения этих задач Коши.
			
			Рассмотрим их Вронскиан:
			\[
			W(\varphi_1, \varphi_2, \dots, \varphi_n, t_0) = \begin{vmatrix}
				1 &0 & \dots &0\\
				0&1&\dots &0\\
				\vdots& \vdots&\ddots &\vdots\\
				0&0&\dots &1\\
			\end{vmatrix}=1.
			\]
			Таким образом, он не равен нулю, а значит эти решения линейно независимы. 
			
			Пусть теперь $\varphi$ -- общее решение исходной системы уравнений, причем $\varphi(t_0) = \begin{bmatrix}
				c_1\\c_2\\\vdots\\c_n
			\end{bmatrix}
			$.
			
			Рассмотрим функцию $\phi(t) = \sum\limits_{k=1}^n c_k \varphi_k(t)$. Заметим, что она также является решением системы. Рассмотрим его значение в точке $t_0$
			\[
			\phi(t_0) = \sum\limits_{k=1}^n c_k \varphi_k(t_0) = \begin{vmatrix}
				c_1\\c_2\\\vdots\\c_n
			\end{vmatrix} = \varphi(t_0).
			\]
			А значит по теореме о совпадении решений получаем, что из совпадения в одной точке решений системы следует совпадение этих решений. А значит решение разложилось в линейную комбинацию $\varphi_i$. То есть $\hc{\varphi_k}_{k=1}^n$ -- базис размерности $n$.
		\end{Proof}
	\end{Th}
	\begin{Def}
		Фундаментальная система решения (ФСР) есть базис в пространстве решений.
	\end{Def}
	\begin{Def}
		Матрица $\hr{\varphi_1, \varphi_2, \dots, \varphi_n}$ для фундаментальной системы решений $\hc{\varphi_k}_{k=1}^n$ называется фундаментальной матрицей.
	\end{Def}
	\begin{Lem}[о множестве фундаментальных матриц]
		Пусть $\Phi$ -- фундаментальная матрица для линейной однородной системы. 
		
		Тогда $\hc{\Phi \cdot M\;|\; M\in M_n(\mathbb{C}) \& \det M \neq 0}$ -- множество всех фундаментальных матриц для этой системы.
		\begin{Proof}
			Пусть $\mathcal{A}$ -- множество фундаментальных решений, а $\mathcal{B} = \hc{\Phi \cdot M\;|\; M\in M_n(\mathbb{C}) \& \det M \neq 0}$.
			
			\begin{itemize}
				\item[$\boxed{\mathcal{A}\subset \mathcal{B}}$] Пусть $\Psi \in \mathcal{A}$.
				\[
				\Psi \underset{\psi_i \text{ -- решение}}{=} \hr{\psi_1, \psi_2, \dots, \psi_n} = \hr{\sum\limits_{k=1}^n c_{1k}\phi_k, \sum\limits_{k=1}^n c_{2k}\phi_k, \dots, \sum\limits_{k=1}^n c_{nk}\phi_k}.
				\]
				Тогда, обозначая $M = \begin{vmatrix}
					c_{11} & c_{21} & \dots & c_{n1} \\
					c_{12} & c_{22} & \dots & c_{n2} \\
					\vdots & \vdots & \ddots & \vdots \\
					c_{1n} & c_{2n} & \dots & c_{nn} \\
				\end{vmatrix}
			$, получаем
			\[
			\Psi = \Phi \cdot M.
			\]
			При этом осталось показать, что определитель $M$ не обнуляется.
			\[
			\underbrace{\det \Psi}_{\neq 0} = \det \Phi \cdot M = \underbrace{\det \Phi}_{\neq 0} \cdot \det M \implies \det M \neq 0.
			\]
			\item[$\boxed{\mathcal{B} \subset \mathcal{A}}$]
			Пусть $\det M \neq 0$. Рассмотрим $\Psi = \Phi \cdot M \in \mathcal B$. Так как $\psi_i$ есть линейная комбинация $\phi_k$, то $\psi_i$ -- решения.
			\[
			W(\psi_1, \psi_2, \dots, \psi_n) = \det \Psi = \det \Phi \cdot \det M \neq 0.
			\]
			Таким образом эти решения линейно независимы, а значит являются фундаментальной системой решений. 
			\end{itemize}
		
		Таким образом, получаем вложения $\mathcal{A} \subset \mathcal{B}$ и $\mathcal{B} \subset \mathcal{A}$. А значит $\mathcal{A} = \mathcal{B}$.
		\end{Proof}
	\end{Lem}

	\begin{Lem}[об овеществлении]
		Пусть $\hc{\varphi_i}_{i=1}^n$ -- фундаментальная система решений в комплексном варианте, причем $\varphi_1 = \overline{\varphi_2}$.
		
		Тогда $\hc{\Re{\varphi_1}}, \hc{\Im{\varphi_1}}, \varphi_3, \dots, \varphi_n$ тоже фундаментальная система решений.
		\begin{Proof}
			Выразим вещественную и мнимую части через ${\varphi_i}_{i=1}^n$:
			\[
			\Re{\varphi_1} = \frac{\varphi_1 + \overline{\varphi_1}}{2} = \frac12 \varphi_1 + \frac12 \varphi_2,
			\]
			\[
			\Re{\varphi_1} = \frac{\varphi_1 + \overline{\varphi_1}}{2} = \frac1{2i} \varphi_1 - \frac1{2i} \varphi_2.
			\]
			Тогда можно записать $\hr{\Re{\varphi_1}}, \hc{\Im{\varphi_1}}, \varphi_3, \dots, \varphi_n = \hr{\varphi_1, \varphi_2, \varphi_3, \dots, \varphi_n} \cdot \begin{bmatrix}
					\frac12 & \frac1{2i} & 0\\
					\frac12 & -\frac1{2i} & 0\\
					\vdots & \vdots & \vdots \\
					0 & 0 & E_{n-2} 
				\end{bmatrix}$. 
			При этом определитель матрицы равен $-\frac1{2i} \neq 0$, а значит это тоже ФСР по предыдущей лемме.
		\end{Proof}
	\end{Lem}
	
	\section[ЛОС с постоянными коэффициентами]{Линейные однородные системы с постоянными коэффициентами}
	\begin{Def}
		Систему $r' = A r$, где $A\in Mat_n(\mathbb{C})$, будем называть линейной однородной системой с постоянными коэффициентами.
	\end{Def}

	\begin{Lem}
		Пусть $\lambda\in spec A$, $h_1, h_2, \dots, h_s$ -- Жорданова цепочка, соответствуюшая $\lambda$. 
		
		Тогда $e^{\lambda t}h_1, e^{\lambda t} (th_1+h_2), \dots, e^{\lambda t} \hr{\frac{t^{s-1}}{(s-1)!} h_1 + \dots + h_{s-1} + h_s}$ -- решения линейной однородной системы с постоянными коэффициентами.
		\begin{Proof}
			\begin{Note}
				Вспомним, что такое Жорданова цепочка.
				Набор $h_1, h_2, \dots, h_s$ такой, что 
				\[
				\begin{split}
				Ah_1 &= \lambda h_1,\\
				\hr{A-\lambda E} h_2 &= h_1\\
				\hr{A-\lambda E} h_3 &= h_2\\
				\dots \\
				\hr{A-\lambda E} h_s &= h_{s-1}\\
				\end{split}
				\]
				называется Жордановой цепочкой.
			\end{Note}
		
			Проверим честной подстановкой
			Пусть $\varphi_k(t) = e^{\lambda t} \sum\limits_{j=1}^k \frac{t^{k-j}}{(k-j)!}h_j$. 
			
			\[
			\begin{split}
			\varphi_k'(t) &= \lambda e^{\lambda t} \sum\limits_{j=1}^k \frac{t^{k-j}}{(k-j)!}h_j + e^{\lambda t} \sum\limits_{j=1}^{k-1} \frac{(k-j)t^{k-j-1}}{(k-j)!}h_j = \\
			&=\lambda e^{\lambda t} \sum\limits_{j=1}^k \frac{t^{k-j}}{(k-j)!}h_j + e^{\lambda t} \sum\limits_{j=1}^{k-1} \frac{t^{k-j-1}}{(k-j-1)!}h_j,
			\end{split}
			\]
			\[
			\begin{split}
				A \cdot \varphi_k(t) &= e^{\lambda t} \sum\limits_{j=1}^k \frac{t^{k-j}}{(k-j)!}A h_j = e^{\lambda t} \frac{t^{k-1}}{(k-1)!}\lambda h_1 + e^{\lambda t} \sum\limits_{j=2}^k \frac{t^{k-j}}{(k-j)!} \hr{\lambda h_j + h_{j-1}}  =\\
				&= e^{\lambda t} \sum\limits_{j=1}^k \frac{t^{k-j}}{(k-j)!}\lambda h_j + e^{\lambda t} \sum\limits_{j=2}^k \frac{t^{k-j}}{(k-j)!}h_{j-1} = \\
				&=  \lambda e^{\lambda t} \sum\limits_{j=1}^k \frac{t^{k-j}}{(k-j)!} h_j + e^{\lambda t} \sum\limits_{j=1}^{k-1} \frac{t^{k-j-1}}{(k-j-1)!}h_{j}.
			\end{split}
			\]
			Таким образом, видно, что $\varphi_k'(t) = A\cdot \varphi_k(t)$, а значит это решение.
		\end{Proof}
	\end{Lem}
	\begin{Lem}[ФСР ЛОС с постоянными коэффициентами]\label{Lem:FSR}
		Фундаментальная система решений линейной однородной системы с постоянными коэффициентами в для Жорданова базиса $\begin{matrix}
			\lambda_1 \leftrightarrow h_1, \dots, h_s\\
			\dots \\
			\lambda_d  \leftrightarrow u_1, \dots, u_m
		\end{matrix}$ 
		есть \[\begin{matrix}
			e^{\lambda_1 t}h_1, e^{\lambda_1 t} (th_1+h_2), \dots, e^{\lambda_1 t} \hr{\frac{t^{s-1}}{(s-1)!} h_1 + \dots + h_{s-1} + h_s}\\
			\dots \\
			e^{\lambda_d t}u_1, e^{\lambda_d t} (tu_1+u_2), \dots, e^{\lambda_d t} \hr{\frac{t^{m-1}}{(m-1)!} h_1 + \dots + h_{m-1} + h_m}
		\end{matrix}\] 
	\begin{Proof}
		Проверим определитель Вронского для этих решений
		\[
		W(\hc{\phi_i},0) = \det \hr{h_1, h_2, \dots, h_s, \dots, u_1, u_2, \dots, u_m} \neq 0.
		\]
		(отличие от нуля есть из-за того, что матрица под детерминантом есть просто базис в $\mathbb{C}^n$).
		Значит это действительно фундаментальная система решений.
	\end{Proof}
	\end{Lem}
	
	\begin{Th}[Формула Остроградского-Лиувилля]
		Пусть есть линейная однородная система $R' = P(t) r$, где $P\in M_n(C(a,b))$, $r_1, \dots, r_n$ -- решения этой системы. 
		
		Тогда \[
		W(r_1, \dots, r_n, t) = W(t_0) \cdot e^{\int\limits_{t_0}^t \tr P(\tau) d\tau}.
		\]
		\begin{Proof}
			Заметим, что написанное выражение очень похоже на решение линейного однородного дифференциального уравнения 1 порядка $y=y_0\cdot e^{\int p}$.
			
			Рассмотрим дифференциальное уравнение $W' = \tr P(t) W$, то есть то, которое дает написанное выражение в качестве решения. Тогда, если Вронскиан удовлетворяет этому уравнению, то он удовлетворяет и написанному выражению.
			
			Рассмотрим, что из себя представляет производная Вронскиана. Запишем определитель по определению
			\[
			W(t) = \det \hr{r_1, \dots, r_n} = \begin{vmatrix}
				r_1^1 & r_2^1 & \dots & r_n^1 \\
				r_1^2 & r_2^2 & \dots & r_n^2 \\
				\vdots  & \vdots & \ddots & \vdots \\
				r_1^n & r_2^n & \dots & r_n^n \\
			\end{vmatrix} = 
			\sum\limits_\pi (-1)^{[\pi]} r_{\pi(1)}^1 r_{\pi(2)}^2 \dots r_{\pi(n)}^n. 
			\]
			Тогда производная 
			\[
			\begin{split}
			W'(t) &= 
			\sum\limits_\pi (-1)^{[\pi]} \hr{\hr{\hr{r_{\pi(1)}^1}' r_{\pi(2)}^2 \dots r_{\pi(n)}^n} + \dots + \hr{r_{\pi(1)}^1 r_{\pi(2)}^2 \dots \hr{r_{\pi(n)}^n}'}} = \\
			&=\det \begin{bmatrix}
				(r_1^1)' & (r_2^1)' & \dots & (r_n^1)' \\
				r_1^2 & r_2^2 & \dots & r_n^2 \\
				\vdots  & \vdots & \ddots & \vdots \\
				r_1^n & r_2^n & \dots & r_n^n \\
			\end{bmatrix}+ \dots + 
	\det \begin{bmatrix}
		r_1^1 & r_2^1 & \dots & r_n^1 \\
		r_1^2 & r_2^2 & \dots & r_n^2 \\
		\vdots  & \vdots & \ddots & \vdots \\
		(r_1^n)' & (r_2^n)' & \dots & (r_n^n)' \\
	\end{bmatrix} = \\
			&=\det \begin{bmatrix}
				R_1'\\R_2\\\vdots\\R_n
			\end{bmatrix}
			+ 
			\det \begin{bmatrix}
				R_1\\R_2'\\\vdots\\R_n
			\end{bmatrix}
			+ 
			\dots +
		\det \begin{bmatrix}
			R_1\\R_2\\\vdots\\R_n'
		\end{bmatrix}.
	\end{split}
			\]
			
			Из того, что $r_1, r_2, \dots, r_n$ -- решения, получаем, что \[\hr{r_1', r_2', \dots r_n'} = P \cdot \hr{r_1, r_2, \dots, r_n}.\]
			А тогда 
			\[
			R_k' = \sum\limits_{j=1}^n [P]_{k,j} R_j.
			\]
			
			Таким образом, 
			\[
			W'(t) = \det \begin{bmatrix}
				\sum\limits_{j=1}^n [P]_{1,j} R_j\\R_2\\\vdots\\R_n
			\end{bmatrix} + \det\begin{bmatrix}
			R_1 \\ \sum\limits_{j=1}^n [P]_{2,j} R_j\\\vdots\\R_n
		\end{bmatrix} + 
	\dots + \det\begin{bmatrix}
		R_1 \\ R_2 \\ \dots \\ \sum\limits_{j=1}^n [P]_{n,j} R_j
	\end{bmatrix} = 
		\]
			По свойству определителя вычтем строки, умноженные на необходимые коэффициенты в каждой матрице  \\
			  \[
			=\det \begin{bmatrix}
				[P]_{1,1}R_1\\R_2\\\vdots\\R_n
			\end{bmatrix}
			+ 
			\det \begin{bmatrix}
				R_1\\ [P]_{2,2} R_2\\\vdots\\R_n
			\end{bmatrix}
			+ 
			\dots +
			\det \begin{bmatrix}
				R_1\\R_2\\\vdots\\ [P]_{n,n}R_n
			\end{bmatrix} =
		\]
		Вынесем коэффициенты из под определителя
		\[
		= \hr{\sum\limits_{j=1}^n [P]_{j,j}} \cdot \det \begin{bmatrix}
			R_1\\R_2\\\vdots\\R_n
		\end{bmatrix}=\tr P \cdot W.
			\]
		\end{Proof}
	\end{Th}

	\section{Неоднородные линейные системы}
	\begin{Th}[общее решение линейной неоднородной системы]
		Пусть $P \in M_n(C(a,b))$, $q\in C\hr{(a,b) \to \mathbb{C}^n}$, $\Phi$ -- фундаментальная матрица соответствующей линейной однородной системы, $\varphi$ -- частное решение линейной системы $r'=P(t) r + q(t)$. 
		
		Тогда общее решение линейной системы есть
		\[
		r = \Phi \cdot C + \varphi, \quad C\in \mathbb{C}^n.
		\]
		
		\begin{Proof}
			Необходимо доказать равенство множеств $A = \hc{r= \Phi \cdot C + \varphi}$ и $B= \hc{\text{множество всех решений}}$.
			\begin{itemize}
			\item[$\boxed{A\subset B}$] Очевидно подстановкой в уравнение.
			\[
			\Phi' \cdot C + \varphi' = P(t) \cdot  \hr{\Phi \cdot C + \varphi} + q(t),
			\]
			\[
			\Phi' \cdot C + \varphi' = P(t) \cdot \Phi \cdot C + P(t) \cdot \varphi + q(t),
			\]
			\[
			\underbrace{\hr{\Phi' -P(t)\cdot \Phi}}_{\stackrel{=0 \text{ , т.к. }}{\text{$\Phi$ -- фундаментальная}}} \cdot C = - \underbrace{\hr{\varphi' - P(t) \varphi - q(t)}}_{\stackrel{=0 \text{ , т.к. }}{\text{$\varphi$ -- решение}}}.
			\]
			
			\item[$\boxed{B\subset A}$] Пусть $r$ -- некоторое решение линейной системы. 
			Тогда $r' = P(t)r+q$ и $\varphi' = P(t) \varphi +q$, а значит, вычитая, получаем 
			\[
			r' - \varphi' = P(t) (r-\varphi), 
			\]
			\[
			(r-\varphi)'=P(t) (r-\varphi),
			\]
			По теореме для однородной линейной системы найдется $C\in \mathbb{C}^n$, что
			\[
			r-\varphi = \Phi \cdot C,
			\]
			\[
			r = \Phi \cdot C + \varphi.
			\]
		\end{itemize}
		\end{Proof}
	\end{Th}

	\begin{Th}[метод вариации постоянных]
		Пусть $P \in M_n(C(a,b))$, $q\in C\hr{(a,b) \to \mathbb{C}^n}$, $\Phi$ -- фундаментальная матрица соответствующей линейной однородной системы. 
		
		Тогда решение линейной системы имеет вид 
		\[
		r = \Phi \cdot C, \quad \text{где } C \text{ -- решение уравнения } \Phi \cdot C' = q.
		\]
		\begin{Proof}
			Найдем решение уравнения $\Phi \cdot C' = q$.
			\[
			C' = \Phi^{-1} q,
			\]
			Так как $\Phi^{-1} = \frac1{\det \Phi} \tilde{\Phi}^{T}$, то правая часть непрерывна, а тогда есть первообразная.
			\[
			C = \int \Phi^{-1} q + A.
			\]
			
			Покажем, что тогда $r=\Phi \hr{\int \Phi^{-1} q + A}$ является общим решением.
			
			\[
			r=\Phi \hr{\int \Phi^{-1} q + A} = \Phi \cdot A + \Phi \int \Phi^{-1} q.
			\]
			Заметим, что оно имеет вид общего решения из предыдущей теоремы, при условии, что $\Phi \int \Phi^{-1} q$ является частным решением. Для проверки этого подставим в исходную линейную систему
			\[
			\hr{\Phi \hr{\int \Phi^{-1} q}}' = P \Phi \hr{\int \Phi^{-1} q}+ q,
			\]
			\[
			\Phi' \int \Phi^{-1} q + \cancel{\hr{\Phi \Phi'} q} = P \Phi \int \Phi^{-1} q + \cancel{q},
			\]
			\[
			\hr{\Phi' - P\Phi} \int \Phi^{-1}q = 0.
			\]
			А это уже верное равенство, так как $\Phi$ -- фундаментальная матрица однородной системы.
			
			Таким образом, получили, что $r=\Phi\cdot C=\Phi \hr{\int \Phi^{-1} q + A}$ имеет вид общего решения системы.
		\end{Proof}
	\end{Th}

	\section{Матричная экспонента}
		\begin{Def}
			Матричной экспонентой матрицы $A$ называется ряд
			\[
			e^A = \sum\limits_{k=0}^{\infty} \frac{A^k}{k!}.
			\]
		\end{Def}
		\begin{Th}[Свойства матричной экспоненты]
			\hspace{0pt}
			\begin{enumerate}
				\item Для любой матрицы $A \in M_n(\mathbb{C})$ ряд $e^A$ сходится.
				\item Если для матриц $A, B$ выполнено $AB=BA$, то $e^{A+B} = e^A e^B$.
				\item $\hr{e^{At}}'_t = A e^{At}$.
				\item Если матрица $A$ представима в виде $A = TJT^{-1}$, то $e^A = T e^J T^{-1}$.
				\item Если матрица $A$ -- диагональная $A = \diag \hr{A_1, \dots, A_d}$, то $e^A = \diag \hr{e^{A_1}, \dots, e^{A_r}}$.
				\item Если есть некоторая Жорданова клетка размера $s$ $J_s(\lambda) = \begin{bmatrix}
					\lambda & 1 & & \dots \\
					 & \lambda & 1 & \dots \\
					\vdots & \vdots & \ddots & \vdots \\
					 & \dots   && \lambda 
				\end{bmatrix}$, то $e^{J_s(\lambda)t} = \begin{bmatrix}
				1 & t & \frac{t^2}{2} & \dots & \frac{t^{s-1}}{(s-1)!} \\
				 & 1 & t & \dots & \frac{t^{s-2}}{(s-2)!} \\
				& & & \ddots & \vdots \\
				& & & & 1
			\end{bmatrix} e^{\lambda t}$ 
			\end{enumerate}
		
			\begin{Proof}
				еще будет
			\end{Proof}
		\end{Th}
		
		\begin{Cor}
			Пусть $A \in M_n (\mathbb{C})$, $r_0 \in \mathbb{C}^n$. 
			
			Тогда $r= e^{A(t-t_0)} r_0$ является решением задачи Коши $\begin{cases}r'=Ar,\\ r(t_0) = r_0.\end{cases}$
			
			\begin{Proof}
				Рассмотрим по третьему свойству
				\[
				\hr{e^{A(t-t_0)}}_t' = A e^{A(t-t_0)}.
				\]
				Тогда, подставляя в уравнение, получаем
				\[
				\hr{e^{A(t-t_0)}r_0}_t' = A e^{A(t-t_0)}r_0,
				\]
				при этом $r(t_0) = e^{A(t_0-t_0)} r_0 = r_0$ и $\det e^{A(t_0-t_0)} = 1$.
				
				А значит $e^{A(t-t_0)}$ является фундаментальной матрицей для системы.
			\end{Proof}
		\end{Cor}
	
		\begin{Note}
			Заметим, что раскладывая в Жорданову форму, получим
			\[
			e^{A(t-t_0)}r_0 = e^{At}\cdot e^{-At_0}r_0 = T e^{Jt} T^{-1} e^{-At_0}r_0 = T e^{Jt} \underbrace{\hr{T^{-1} e^{-At_0}r_0}}_{C} = Te^{Jt} C.
			\]
			Таким образом, между $C$ и $r_0$ устанавливается биекция.
			
			Тогда, вспоминая, что $T = \hr{h_1, \dots, h_s, \dots, v_1, \dots, v_d}$, придем к решению линейной однородной системы с постоянными коэффициентами \ref{Lem:FSR}
			\[
			Te^{Jt} = \hr{e^{\lambda t}h_1, e^{\lambda t} (th_1+h_2), \dots, e^{\lambda t} \hr{\frac{t^{s-1}}{(s-1)!} h_1 + \dots + h_{s-1} + h_s}, \dots}.
			\]
		\end{Note}
\end{document}













